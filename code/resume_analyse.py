from langgraph.constants import END
from langgraph.graph import StateGraph
import jieba
from keybert import KeyBERT
from langchain_core.tools import tool
from langgraph.types import Command
from sentence_transformers import SentenceTransformer, util
from langchain_core.prompts import ChatPromptTemplate,SystemMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_core.messages import AIMessage
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Circle
from matplotlib import patheffects
from llama_index.core.schema import TextNode
from llama_index.readers.file import PDFReader
from pathlib import Path
from typing import Annotated
import api_key
from langchain_community.utilities import GoogleSerperAPIWrapper
from base import llm_google,llm,llm_qwen
import os
import re
from  callbacks import  llm_callback_handler
from state import MainState,ResumeEvaluateInPut,ResumeEvaluateState
from state import CodeTestOutPut as ResumeEvaluateOutPut
from generate_doc import create_resume_assessment_report
@tool(description="è°ƒç”¨æœç´¢å¼•æ“")
def web_search(query: Annotated[str, "è¾“å…¥è¦æœç´¢çš„å†…å®¹"]) -> str:
        searches = GoogleSerperAPIWrapper()
        return searches.run(query)
def analyze_resume(resume: MainState) -> dict:
    """
    åˆ†æç®€å†PDFæ–‡ä»¶ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯å¹¶è¿”å›TextNodeåˆ—è¡¨å’ŒResumeå­—å…¸
    å‚æ•°:
        resume: åŒ…å«'path'é”®çš„å­—å…¸ï¼ŒæŒ‡å®šPDFæ–‡ä»¶è·¯å¾„
    è¿”å›:
        Resume: ç»“æ„åŒ–ç®€å†æ•°æ®
    """
    job=resume['job']
    path = resume.get('path', '')
    headers = {
        "æ•™è‚²ç»å†": "school",
        "é¡¹ç›®ç»å†": "program",
        "å·¥ä½œç»å†": "work",
        "å®ä¹ ç»å†": "work",
        "ä¸“ä¸šæŠ€èƒ½": "technology_stack",
        "æŠ€èƒ½æ ˆ": "technology_stack",
        "è£èª‰å¥–é¡¹": "awards",
        "ä¸ªäººä¼˜åŠ¿": "technology_stack",
        "è·å¥–æƒ…å†µ": "awards",
        "å¿—æ„¿è€…æœåŠ¡ç»å†":"school_work",
        "ç¤¾å›¢/ç»„ç»‡ç»å†": "school_work",
    }
    resume_data = {
        "resume_text": "",
        "program": "",
        "work": "",
        "school": "",
        "technology_stack": "",
        "awards": "",
        "school_work":""
    }
    loader = PDFReader()
    file_path = Path(path)
    documents = loader.load_data(file=file_path)
    nodes = []
    full_text = "\n".join([doc.get_content() for doc in documents])
    resume_data["resume_text"] = full_text
    base_metadata = documents[0].metadata if documents else {}
    regex_pattern = '|'.join(map(re.escape, headers.keys()))
    header_matches = list(re.finditer(regex_pattern, full_text))

    if not header_matches:
        if full_text.strip():
            nodes.append(TextNode(
                text=full_text.strip(),
                metadata={**base_metadata, "header": "æ–‡æ¡£å…¨æ–‡"}
            ))
        return {'resume':resume_data}

    # å¤„ç†æ ‡é¢˜å‰çš„å†…å®¹
    first_header_start = header_matches[0].start()
    if first_header_start > 0:
        content = full_text[:first_header_start].strip()
        if content:
            nodes.append(TextNode(
                text=content,
                metadata={**base_metadata, "header": "æ±‚èŒåŸºæœ¬ä¿¡æ¯"}
            ))

    # éå†æ‰€æœ‰æ ‡é¢˜å¹¶æå–å†…å®¹
    for i, match in enumerate(header_matches):
        header = match.group(0)
        content_start = match.end()
        content_end = header_matches[i + 1].start() if i < len(header_matches) - 1 else len(full_text)
        content_block = full_text[content_start:content_end].strip()

        if content_block:
            # æ·»åŠ åˆ°TextNode
            final_text = f"{header}\n{content_block}"
            nodes.append(TextNode(
                text=final_text,
                metadata={**base_metadata, "header": header}
            ))

            # æ ¹æ®æ ‡é¢˜ç±»å‹å¡«å……Resumeç»“æ„
            field = headers.get(header)
            if field:
                resume_data[field] += f"{content_block}\n"
    # æ¸…ç†å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ
    for key in resume_data.keys():
        resume_data[key] = resume_data[key].strip()
    return {'resume': resume_data,'job':job}


async def get_resume_key_score(resume: ResumeEvaluateInPut) -> dict:
    """"å°†ç”¨æˆ·ç®€å†å’Œåº”è˜å²—ä½è¿›è¡ŒæŠ€èƒ½åŒ¹é…åº¦åˆ†æå¹¶è¿”å›åŒ¹é…åˆ†æ•°ï¼ˆæ»¡åˆ†100åˆ†ï¼‰"""
    resume=resume.get('resume',{})
    os.environ["SERPER_API_KEY"] = api_key.search_api_key
    encode_path = r""  # sentenc-transformer æ¨¡å‹  æˆ‘ä½¿ç”¨çš„æ˜¯ shibing624text2vec-base-chinese
    STOPWORDS_FILE_PATH = r"stopwords-mast/stopwords-master/scu_stopwords.txt"
    model_for_keybert = SentenceTransformer(
        encode_path,
        backend="onnx",
        device="cuda",
        model_kwargs={
            "file_name": "model_O4.onnx",
            "provider": "CUDAExecutionProvider"
        }
    )
    kw_model = KeyBERT(model=model_for_keybert)



    def load_chinese_stopwords(filepath):
        """åŠ è½½ä¸­æ–‡åœç”¨è¯"""
        if not os.path.exists(filepath):
            print(f"é”™è¯¯: åœç”¨è¯æ–‡ä»¶ '{filepath}' ä¸å­˜åœ¨ã€‚è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
            return []
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                stopwords = [line.strip() for line in f if line.strip()]
            print(f"æˆåŠŸåŠ è½½ {len(stopwords)} ä¸ªä¸­æ–‡åœç”¨è¯ä» '{filepath}'ã€‚")
            return stopwords
        except Exception as e:
            print(f"åŠ è½½åœç”¨è¯æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []

    def extract_keybert_keywords(text, kw_model, stopwords_list, top_n=10, diversity=0.5):
        segmented_text = " ".join(jieba.lcut(text))
        keywords_with_scores = kw_model.extract_keywords(
            segmented_text,
            keyphrase_ngram_range=(3, 7),  # æå–3åˆ°7ä¸ªè¯çš„çŸ­è¯­
            stop_words=stopwords_list,  # ä¼ å…¥ä¸­æ–‡åœç”¨è¯åˆ—è¡¨
            top_n=top_n,  # æå–å‰Nä¸ªå…³é”®è¯
            use_mmr=True,  # ä½¿ç”¨æœ€å¤§è¾¹é™…ç›¸å…³æ€§ï¼Œå¢åŠ å…³é”®è¯å¤šæ ·æ€§
            diversity=diversity  # å¤šæ ·æ€§å‚æ•°
        )
        return [kw[0] for kw in keywords_with_scores]
    print("æ­£åœ¨è¿›è¡Œç®€å†æŠ€æœ¯æ ˆåŒ¹é…åˆ†æ")
    resume_text = resume.get('program', '') + '\n' + resume.get('work', '') + '\n' + resume.get('technology_stack', '')
    job_description_text = resume.get('job', '')
    system_prompt_template = """
# è§’è‰²
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç®€å†è¯„ä¼°ä¸“å®¶å’ŒèŒä¸šå‘å±•é¡¾é—®ã€‚ä½ çš„ä»»åŠ¡æ˜¯é€šè¿‡æ·±åº¦åˆ†æå²—ä½æŠ€èƒ½éœ€æ±‚ï¼Œå¯¹ç”¨æˆ·ç®€å†çš„æŠ€æœ¯æ ˆè¿›è¡Œä¸€æ¬¡**ç»“æ„åŒ–ã€å¯è§†åŒ–ã€æå…·æ´å¯ŸåŠ›**çš„ä¸“ä¸šè¯„ä»·ï¼Œå¹¶æä¾› actionable çš„å»ºè®®ã€‚

# æ ¸å¿ƒä»»åŠ¡
ä½ çš„å›ç­”å¿…é¡»åŒ…å«ä»¥ä¸‹å…­ä¸ªæ–¹é¢çš„å®Œæ•´åˆ†æï¼Œç‰¹åˆ«æ˜¯æ ¸å¿ƒæŠ€æœ¯æ ˆçš„å¯¹æ¯”åˆ†æéœ€è¦ä»¥ä¸€ä¸ª**é«˜åº¦ç»“æ„åŒ–çš„è¯Šæ–­è¡¨æ ¼**å‘ˆç°ã€‚
---

## 1. æ€»ä½“è¯„ä»·ä¸åŒ¹é…åº¦

*   **æ€»ä½“ç¬¦åˆåº¦ï¼š** [é«˜/ä¸­é«˜/ä¸­/ä¸­ä½/ä½]
*   **æ ¸å¿ƒäº®ç‚¹ï¼š** [ç®€è¦æ¦‚è¿°å€™é€‰äººæŠ€æœ¯æ ˆä¸å²—ä½è¦æ±‚é«˜åº¦åŒ¹é…çš„å‡ ä¸ªå…³é”®ç‚¹ã€‚]
*   **ä¸»è¦å·®è·ï¼š** [ç®€è¦æŒ‡å‡ºå€™é€‰äººæŠ€æœ¯æ ˆä¸å²—ä½è¦æ±‚å­˜åœ¨çš„ä¸»è¦å·®è·æˆ–ä¸è¶³ã€‚]

## 2. æ ¸å¿ƒæŠ€æœ¯æ ˆè¯Šæ–­è¡¨ (Detailed Diagnosis Table)

è¯·ä½¿ç”¨ä»¥ä¸‹**é«˜åº¦ç»“æ„åŒ–çš„è¡¨æ ¼**ï¼Œå¯¹å²—ä½è¦æ±‚ä¸å€™é€‰äººæŠ€æœ¯æ ˆè¿›è¡Œæ·±åº¦åŒ¹é…åˆ†æã€‚

**å›¾ä¾‹è¯´æ˜:**
*   **åŒ¹é…åº¦ âœ…:** é«˜åº¦åŒ¹é…ï¼Œæ˜¯æ˜ç¡®çš„ä¼˜åŠ¿é¡¹ã€‚
*   **åŒ¹é…åº¦ ğŸŸ¡:** ä¸­ç­‰åŒ¹é…ï¼ŒåŸºæœ¬æ»¡è¶³è¦æ±‚ä½†æœ‰æå‡ç©ºé—´ï¼Œæˆ–æŒæ¡äº†ç›¸å…³ä½†éé¦–é€‰çš„æŠ€æœ¯ã€‚
*   **åŒ¹é…åº¦ âŒ:** å­˜åœ¨å·®è·ï¼Œæ˜¯æ˜æ˜¾çš„çŸ­æ¿æˆ–æŠ€èƒ½ç¼ºå¤±ã€‚

| æŠ€æœ¯é¢†åŸŸ (Tech Domain) | å²—ä½å…·ä½“è¦æ±‚ (Specific Requirement) | ç®€å†ä½“ç° (Resume Evidence) | åŒ¹é…åº¦ (Match) | è¯„ä»·ä¸åˆ†æ (Evaluation & Analysis) | æå‡å»ºè®® (Actionable Suggestion) |
|---|---|---|---|
| **åç«¯å¼€å‘** | é«˜å¹¶å‘å¾®æœåŠ¡æ¶æ„ (Go/Java) | å¤šä¸ªé¡¹ç›®ä½¿ç”¨Goå’ŒGinæ¡†æ¶ï¼ŒæåŠQPSä¼˜åŒ–ç»éªŒã€‚ | âœ… | **ä¼˜åŠ¿é¡¹ã€‚** å€™é€‰äººçš„GoæŠ€æœ¯æ ˆä¸å²—ä½è¦æ±‚é«˜åº¦å¥‘åˆï¼Œä¸”å…·å¤‡é«˜å¹¶å‘å®è·µç»éªŒï¼Œè¿™æ˜¯æ ¸å¿ƒç«äº‰åŠ›ã€‚ | å¯ä»¥åœ¨é¢è¯•ä¸­å‡†å¤‡ä¸€ä¸ªèƒ½ä½“ç°æ¶æ„è®¾è®¡æ·±åº¦çš„é¡¹ç›®æ¡ˆä¾‹ã€‚ |
| **å‰ç«¯å¼€å‘** | ç²¾é€šReactï¼Œç†Ÿæ‚‰å…¶ç”Ÿæ€ (Redux/Hooks) | æŒæ¡Vue.jsï¼Œæœ‰å¤šä¸ªVueé¡¹ç›®ç»éªŒï¼ŒæœªæåŠReactã€‚ | ğŸŸ¡ | **å­˜åœ¨æ¡†æ¶å·®å¼‚ã€‚** è™½ç„¶å‰ç«¯åŸºç¡€æ‰å®ï¼Œä½†ä¸å²—ä½é¦–é€‰çš„ReactæŠ€æœ¯æ ˆä¸ç¬¦ã€‚ | **é«˜ä¼˜å…ˆçº§ã€‚** å»ºè®®ç«‹å³å¼€å§‹å­¦ä¹ Reactï¼Œå¹¶å®Œæˆ1-2ä¸ªä½¿ç”¨React Hookså’ŒReduxçš„ä¸ªäººé¡¹ç›®ã€‚ |
| **æ•°æ®åº“** | MySQLè®¾è®¡ä¸ä¼˜åŒ–ï¼Œæœ‰NoSQLå®è·µç»éªŒ | ç†Ÿæ‚‰MySQLå’ŒSQLä¼˜åŒ–ï¼ŒæœªæåŠNoSQLã€‚ | ğŸŸ¡ | **æ»¡è¶³éƒ¨åˆ†è¦æ±‚ã€‚** MySQLç»éªŒç¬¦åˆè¦æ±‚ï¼Œä½†ç¼ºä¹NoSQLå®è·µæ˜¯çŸ­æ¿ï¼Œå¯èƒ½æ— æ³•åº”å¯¹å²—ä½å¯¹ç¼“å­˜æˆ–å¤§æ•°æ®åœºæ™¯çš„éœ€æ±‚ã€‚ | å­¦ä¹ Redisæˆ–MongoDBï¼Œå¹¶åœ¨ä¸ªäººé¡¹ç›®ä¸­é›†æˆï¼Œé‡ç‚¹ç†è§£å…¶é€‚ç”¨åœºæ™¯å’Œæ•°æ®æ¨¡å‹ã€‚ |
| **DevOps** | ç†Ÿæ‚‰CI/CD, Docker, Kubernetes(K8s) | ç†Ÿæ‚‰Dockerå’ŒJenkinsï¼ŒæœªæåŠK8sã€‚ | âŒ | **å­˜åœ¨å…³é”®å·®è·ã€‚** æŒæ¡Dockeræ˜¯åŸºç¡€ï¼Œä½†ç¼ºä¹K8sç»éªŒæ„å‘³ç€åœ¨ç°ä»£äº‘åŸç”Ÿéƒ¨ç½²å’Œç®¡ç†æ–¹é¢å­˜åœ¨æ˜æ˜¾çŸ­æ¿ã€‚ | å­¦ä¹ Kubernetesæ ¸å¿ƒæ¦‚å¿µï¼ˆPod, Service, Deploymentï¼‰ï¼Œå¹¶å°è¯•ç”¨Minikubeåœ¨æœ¬åœ°æ­å»ºä¸€ä¸ªç®€å•çš„åº”ç”¨ã€‚ |


**è¡¨æ ¼å¡«å†™è¯´æ˜ï¼š**
*   **æŠ€æœ¯é¢†åŸŸï¼š** å¯¹æŠ€æœ¯è¿›è¡Œåˆ†ç±»ï¼Œå¦‚åç«¯ã€staticã€æ•°æ®åº“ã€DevOpsã€æµ‹è¯•ã€æ•°æ®åˆ†æç­‰ã€‚
*   **å²—ä½å…·ä½“è¦æ±‚ï¼š** æ·±å…¥è§£è¯»JDï¼Œæç‚¼å‡ºå¯¹æŠ€èƒ½çš„å…·ä½“è¦æ±‚ï¼ˆä¾‹å¦‚ï¼Œè¦æ±‚Pythonï¼Œæ˜¯ç”¨äºæ•°æ®åˆ†æè¿˜æ˜¯Webå¼€å‘ï¼Ÿï¼‰ã€‚
*   **ç®€å†ä½“ç°ï¼š** æ‰¾åˆ°ç®€å†ä¸­èƒ½è¯æ˜è¯¥æŠ€èƒ½çš„å¯¹åº”æè¿°ã€‚
*   **åŒ¹é…åº¦ï¼š** ä½¿ç”¨ âœ…, ğŸŸ¡, âŒ è¿›è¡Œå¯è§†åŒ–è¯„ä¼°ã€‚
*   **è¯„ä»·ä¸åˆ†æï¼š** **åªè¯„ä»·ï¼Œä¸ç»™å»ºè®®ã€‚** ç®€æ´è¯´æ˜ä¸ºä»€ä¹ˆç»™å‡ºæ­¤åŒ¹é…åº¦ï¼Œç‚¹å‡ºä¼˜åŠ£åŠ¿ã€‚
*   **æå‡å»ºè®®ï¼š** **åªç»™å»ºè®®ï¼Œä¸è¯„ä»·ã€‚** ç»™å‡ºå…·ä½“ã€å¯æ“ä½œçš„æå‡æ–¹æ³•ã€‚

## 3. ä¼˜åŠ¿æŠ€æœ¯æ ˆä¸äº®ç‚¹

*   [åŸºäºè¯Šæ–­è¡¨çš„ âœ… é¡¹ï¼Œè¯¦ç»†å±•å¼€è¯´æ˜å€™é€‰äººçš„æ ¸å¿ƒä¼˜åŠ¿åŠå…¶å¯¹å²—ä½çš„ä»·å€¼ã€‚]
*   [æŒ‡å‡ºç®€å†ä¸­å¯èƒ½è¢«ä½ä¼°ä½†å¯¹å²—ä½æœ‰æ½œåœ¨ä»·å€¼çš„æŠ€èƒ½æˆ–ç‰¹è´¨ï¼ˆä¾‹å¦‚ï¼ŒæŸé¡¹æŠ€æœ¯çš„åº•å±‚åŸç†ç†è§£ã€ä¼˜ç§€çš„å¼€æºè´¡çŒ®ç­‰ï¼‰ã€‚]

## 4. å¾…æå‡æŠ€æœ¯æ ˆä¸å·®è·åˆ†æ

*   [åŸºäºè¯Šæ–­è¡¨çš„ âŒ å’Œ ğŸŸ¡ é¡¹ï¼Œæ˜ç¡®æŒ‡å‡ºå€™é€‰äººéœ€è¦å¼¥è¡¥çš„æ ¸å¿ƒæŠ€èƒ½å·®è·ã€‚]
*   [åˆ†æè¿™äº›å·®è·å¯èƒ½å¯¹å€™é€‰äººèƒœä»»è¯¥å²—ä½å¸¦æ¥çš„å…·ä½“å½±å“ï¼Œä¾‹å¦‚â€œç¼ºä¹K8sç»éªŒå¯èƒ½ä¼šåœ¨å…¥èŒåéš¾ä»¥å¿«é€Ÿå‚ä¸åˆ°é¡¹ç›®çš„éƒ¨ç½²æµç¨‹ä¸­â€ã€‚]

## 5. é’ˆå¯¹æ€§è¡ŒåŠ¨è®¡åˆ’ (Action Plan)

1.  **æŠ€èƒ½æå‡è·¯çº¿å›¾ (Skill Roadmap):**
    *   **é«˜ä¼˜å…ˆçº§ (0-1ä¸ªæœˆ):** [é’ˆå¯¹ âŒ é¡¹ï¼Œç»™å‡ºæœ€ç´§æ€¥çš„å¼¥è¡¥å»ºè®®ï¼Œå¦‚ï¼šå­¦ä¹ KubernetesåŸºç¡€ã€‚]
    *   **ä¸­ä¼˜å…ˆçº§ (1-3ä¸ªæœˆ):** [é’ˆå¯¹ ğŸŸ¡ é¡¹ï¼Œç»™å‡ºå®Œå–„å»ºè®®ï¼Œå¦‚ï¼šæ·±å…¥å­¦ä¹ NoSQLæ•°æ®åº“ã€‚]
2.  **ç®€å†ä¼˜åŒ–å»ºè®® (Resume Polish):**
    *   [å¦‚æœç®€å†ä¸­æŸäº›æŠ€èƒ½æœªèƒ½å……åˆ†ä½“ç°ï¼Œç»™å‡ºå¦‚ä½•æ›´å¥½åœ°åœ¨ç®€å†ä¸­çªå‡ºè¿™äº›æŠ€èƒ½çš„å»ºè®®ã€‚ä¾‹å¦‚ï¼šâ€œå»ºè®®å°†Goé¡¹ç›®ä¸­çš„å¹¶å‘ä¼˜åŒ–ç»éªŒå•ç‹¬ä½œä¸ºä¸€ç‚¹åˆ—å‡ºï¼Œå¹¶ç”¨æ•°æ®è¯´æ˜ä¼˜åŒ–æˆæœã€‚â€]
3.  **é¢è¯•å‡†å¤‡ç­–ç•¥ (Interview Strategy):**
    *   [é’ˆå¯¹æ€§åœ°å»ºè®®å€™é€‰äººå¦‚ä½•å‡†å¤‡é¢è¯•ã€‚ä¾‹å¦‚ï¼šâ€œå½“è¢«é—®åŠReactç»éªŒæ—¶ï¼Œå¯ä»¥è¯šå®è¯´æ˜ç›®å‰åœ¨å­¦ä¹ ä¸­ï¼Œå¹¶ä¸»åŠ¨å°†è¯é¢˜å¼•å¯¼åˆ°ä½ ç²¾é€šçš„Vueä¸Šï¼Œé€šè¿‡å¯¹æ¯”ä¸¤è€…æ¥å±•ç°ä½ çš„å‰ç«¯çŸ¥è¯†æ·±åº¦å’Œå­¦ä¹ èƒ½åŠ›ã€‚â€]

## 6. æ€»ç»“
[é‡ç”³æ ¸å¿ƒè§‚ç‚¹ï¼Œå¹¶ç»™å‡ºæœ€ç»ˆçš„ç»¼åˆè¯„ä»·ï¼Œæ€»ç»“å€™é€‰äººåœ¨æ­¤å²—ä½ä¸Šçš„æ½œåŠ›å’ŒæŒ‘æˆ˜ã€‚]
---
"""
    prompt = SystemMessagePromptTemplate.from_template(system_prompt_template)
    chain = prompt | llm_google | StrOutputParser()
    chain=chain.with_config({'callbacks':llm_callback_handler})
    response = await chain.ainvoke(
        {'messages': [HumanMessage(content=resume_text + '\niåº”è˜å²—ä½ä¿¡æ¯ï¼š\n' + job_description_text)]})
    print(response)
    chinese_stopwords_list = load_chinese_stopwords(STOPWORDS_FILE_PATH)
    if not chinese_stopwords_list:
        print("æœªåŠ è½½åˆ°ä»»ä½•åœç”¨è¯ï¼Œç¨‹åºç»ˆæ­¢ã€‚è¯·æ£€æŸ¥åœç”¨è¯æ–‡ä»¶è·¯å¾„å’Œå†…å®¹ã€‚")
        exit()
    match_threshold = 0.70  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå¯ä»¥æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´
    matched_pairs = []
    total_similarity_score = 0
    matched_count = 0
    key_weight = 0.7
    similarity_weight = 0.3
    top_n = 15
    resume_text=resume.get('technology_stack', '')
    resume_keywords_keybert = extract_keybert_keywords(resume_text, kw_model, chinese_stopwords_list, top_n=top_n,
                                                       diversity=0.4)
    job_keywords_keybert = extract_keybert_keywords(job_description_text, kw_model, chinese_stopwords_list, top_n=top_n,
                                                    diversity=0.4)
    print(f"ç®€å†å…³é”®è¯: {resume_keywords_keybert}")
    print(f"å²—ä½å…³é”®è¯: {job_keywords_keybert}")
    model_for_comparison = model_for_keybert
    print("\n--- å…³é”®è¯è¯­ä¹‰åŒ¹é… ---")
    # ç¼–ç å…³é”®è¯
    resume_embeddings_keybert = model_for_comparison.encode(resume_keywords_keybert, convert_to_tensor=True)
    job_embeddings_keybert = model_for_comparison.encode(job_keywords_keybert, convert_to_tensor=True)

    for i, r_kw in enumerate(resume_keywords_keybert):
        best_match_score = 0
        best_match_j_kw = None

        for j, j_kw in enumerate(job_keywords_keybert):
            similarity = util.cos_sim(resume_embeddings_keybert[i], job_embeddings_keybert[j]).item()

            if similarity > best_match_score:
                best_match_score = similarity
                best_match_j_kw = j_kw

        if best_match_score >= match_threshold:
            matched_pairs.append((r_kw, best_match_j_kw, best_match_score))
            total_similarity_score += best_match_score
            matched_count += 1

    print("\nåŒ¹é…ç»“æœ (ç®€å†å…³é”®è¯ -> å²—ä½å…³é”®è¯):")
    for r_kw, j_kw, score in sorted(matched_pairs, key=lambda x: x[2], reverse=True):
        print(f"'{r_kw}' <-> '{j_kw}' (ç›¸ä¼¼åº¦: {score:.2f})")
    overall_match_score = total_similarity_score / matched_count if matched_count > 0 else 0
    print(f"\næ€»åŒ¹é…å…³é”®è¯æ•°é‡: {matched_count}")
    print(f"å¹³å‡åŒ¹é…ç›¸ä¼¼åº¦: {overall_match_score:.2f}")
    print("\n--- æ•´ä½“æ–‡æ¡£ç›¸ä¼¼åº¦ (ä½¿ç”¨ KeyBERT å†…éƒ¨æ¨¡å‹) ---")
    resume_embedding_doc = model_for_comparison.encode(resume_text, convert_to_tensor=True)
    job_embedding_doc = model_for_comparison.encode(job_description_text, convert_to_tensor=True)
    doc_similarity = util.cos_sim(resume_embedding_doc, job_embedding_doc).item()
    print(f"ç®€å†ä¸å²—ä½æè¿°æ•´ä½“ç›¸ä¼¼åº¦: {doc_similarity:.2f}")
    sum_score = doc_similarity * similarity_weight + overall_match_score * key_weight
    print(f"æœ€ç»ˆå¾—åˆ†ä¸ºï¼š{sum_score}")
    print("ç®€å†æŠ€æœ¯æ ˆåŒ¹é…åˆ†æç»“æŸ")
    return {'technology_stack_evaluate': response, 'technology_stack_score': sum_score * 100}


async def get_school_score(resume: ResumeEvaluateInPut) -> dict:
    """è·å–é™¢æ ¡è¯„åˆ†"""
    resum= resume.get('resume', {})
    print("æ­£åœ¨è¿›è¡Œé™¢æ ¡èƒŒæ™¯åˆ†æ")
    school = resum.get('school', '')
    job = resum.get('job', '')
    contents=school + '\n'+'åº”è˜å²—ä½ä¿¡æ¯ï¼š\n' + job
    prompt_template = """
    ä½ æ˜¯ä¸€ä¸ªå­¦å†è¯„ä¼°ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡å¯¹ç”¨æˆ·æä¾›çš„å­¦å†ä¿¡æ¯ï¼Œä¾ç…§å²—ä½è¦æ±‚çš„å­¦å†ä»¥åŠå­¦ç§‘è¦æ±‚ï¼Œè¿›è¡Œå­¦å†èƒŒæ™¯è¯„åˆ†
    ä½ çš„å·¥ä½œå®‰æ’ï¼š
    é¦–å…ˆå€ŸåŠ©æœç´¢å·¥å…·å¯¹ç”¨æˆ·æä¾›çš„è‡ªå·±å­¦å†èµ„æ–™è¿›è¡Œå……åˆ†è°ƒç ”
    å½“è®¤ä¸ºå·²ç»å……åˆ†æŒæ¡ç”¨æˆ·æä¾›æä¾›å­¦å†çš„èµ„æ–™åï¼Œä¾ç…§å²—ä½è¿›è¡Œä¸“ä¸šæ€§è¯„åˆ†ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    åˆ¤æ–­æ ‡å‡†ï¼š
    å¦‚æœç®€å†ä¸­æ²¡æœ‰å¯¹å­¦å†è¿›è¡Œè¦æ±‚ï¼Œé‚£ä¹ˆä½ å°±éœ€è¦å¯¹ä»å­¦æ ¡å±‚é¢è¿›è¡Œæ‰“åˆ†ï¼Œä¾‹å¦‚å­¦ç§‘å®åŠ›ï¼Œå­¦æ ¡èƒŒæ™¯ç­‰ç­‰
    æœ€ç»ˆç­”æ¡ˆæ ¼å¼è¦æ±‚ï¼š
    ä»¥jsonçš„æ ¼å¼è¾“å‡º
    school_score å¯¹åº”å­—æ®µç±»å‹ä¸º float è¡¨ç¤ºå­¦å†èƒŒæ™¯ä¸å²—ä½è¦æ±‚çš„åŒ¹é…å¾—åˆ†ï¼ˆæ»¡åˆ†100 80-100 è¡¨ç¤ºè¾¾åˆ°è¦æ±‚ï¼Œä¸”é«˜äºå²—ä½å­¦å†è¦æ±‚ï¼Œ60-80 è¡¨ç¤ºè¾¾åˆ°å²—ä½è¦æ±‚ã€‚60ä»¥ä¸‹ è¡¨ç¤ºæœªè¾¾åˆ°å²—ä½ï¼Œå±äºä¸åŠæ ¼ï¼‰
    æ³¨æ„ä¸¥æ ¼æŒ‰ç…§è¯¥æ ¼å¼è¾“å‡º
    """
    agent = create_react_agent(llm, [web_search], prompt=prompt_template)
    agent= agent.with_config({'callbacks': llm_callback_handler})
    response = await agent.ainvoke({'messages': [HumanMessage(content=contents)]})
    try:
        ans=response['messages'][-1]
        parse=JsonOutputParser()
        if isinstance(ans,AIMessage):
            ans=parse.parse(ans.content)
            print(ans)
            print("é™¢æ ¡èƒŒæ™¯åˆ†æç»“æŸ")
            return ans
    except Exception as e:
        print(e)
        return {'school_score': 60}


async def get_potential_score(resume: ResumeEvaluateInPut) -> dict:
    """è·å–æœªæ¥æ½œåŠ›è¯„åˆ†"""
    print("æ­£åœ¨è¿›è¡Œæœªæ¥æ½œåŠ›åˆ†æ")
    resume = resume.get('resume', {})
    text = resume.get('resume_text', '')
    job = resume.get('job', '')
    system_prompt_template = """
        ä½ æ˜¯ä¸€åèµ„æ·±çš„äººæ‰åˆ†æå¸ˆå’Œæ½œåŠ›è¯„ä¼°ä¸“å®¶ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯åŸºäºæä¾›çš„ç®€å†ä¿¡æ¯å’Œå²—ä½æè¿°ï¼Œ
        å¯¹å€™é€‰äººåœ¨è¯¥å²—ä½ä¸Šçš„èƒœä»»æ½œåŠ›è¿›è¡Œå…¨é¢ã€æ·±å…¥ä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„è¯„ä¼°ã€‚ä½ çš„åˆ†æå¿…é¡»è¶…è¶Šç®€å•çš„å…³é”®è¯åŒ¹é…ï¼Œå……åˆ†æŒ–æ˜å³ä½¿åœ¨ç®€å†ä¸­æ²¡æœ‰æ˜ç¡®æåŠï¼Œ
        ä½†é€šè¿‡å…¶ä»–ç»å†ã€æˆå°±ã€é¡¹ç›®ã€æ•™è‚²èƒŒæ™¯æˆ–ä¸ªäººç‰¹è´¨èƒ½å¤Ÿä¾§é¢è¯æ˜å…¶åœ¨è¯¥å²—ä½ä¸Šå…·å¤‡å¼ºå¤§èƒœä»»æ½œåŠ›çš„æ–¹é¢ã€‚
        ä½ éœ€è¦åƒä¸€åç»éªŒä¸°å¯Œçš„æ‹›è˜å®˜æˆ–çŒå¤´ä¸€æ ·ï¼Œè¯†åˆ«å¯è¿ç§»æŠ€èƒ½ã€å­¦ä¹ èƒ½åŠ›ã€è§£å†³é—®é¢˜çš„èƒ½åŠ›ã€
        ä»¥åŠä¸å²—ä½æ ¸å¿ƒè¦æ±‚ç›¸å…³çš„é—´æ¥è¯æ®ã€‚
        ä½ å¯ä»¥ä»ä¸‹é¢å‡ ä¸ªç‚¹è¿›è¡Œç»¼åˆè¯„ä¼°
        1.  **æ ¸å¿ƒæŠ€èƒ½ä¸ç»éªŒåŒ¹é…åº¦ (Core Skills & Experience Match):**
            *   ã€ç›´æ¥åŒ¹é…ã€‘ï¼šç®€å†ä¸­æ˜ç¡®æåŠçš„ï¼Œä¸å²—ä½è¦æ±‚ç›´æ¥ç›¸å…³çš„å…³é”®æŠ€èƒ½ã€å·¥å…·ã€è¡Œä¸šç»éªŒã€é¡¹ç›®ç»éªŒå’Œæˆå°±ã€‚
        2.  **å¯è¿ç§»èƒ½åŠ›ä¸æ½œåŠ›æŒ–æ˜ (Transferable Skills & Potential Excavation):**
            *   ã€æŠ€èƒ½è¿ç§»ã€‘ï¼šå³ä½¿å²—ä½è¦æ±‚æœªç›´æ¥æåŠï¼Œä½†ä»å…¶ä»–å·¥ä½œã€é¡¹ç›®æˆ–ä¸ªäººç»å†ä¸­ä¹ å¾—ï¼Œå¯é«˜åº¦åº”ç”¨äºæœ¬å²—ä½çš„é€šç”¨æˆ–ä¸“ä¸šæŠ€èƒ½ï¼ˆä¾‹å¦‚ï¼šè·¨éƒ¨é—¨åä½œã€æ•°æ®åˆ†æã€å¤æ‚ç³»ç»Ÿé›†æˆã€ç”¨æˆ·ç ”ç©¶ã€å†…å®¹åˆ›ä½œã€å¸‚åœºæ´å¯Ÿã€æµç¨‹ä¼˜åŒ–ç­‰ï¼‰
            *   ã€å­¦ä¹ èƒ½åŠ›ä¸é€‚åº”æ€§ã€‘ï¼šä»æ•™è‚²èƒŒæ™¯ã€èŒä¸šè½¬å‹ã€æ–°é¢†åŸŸæ¢ç´¢ã€å¿«é€ŸæŒæ¡æ–°å·¥å…·/æŠ€æœ¯ã€åº”å¯¹å˜åŒ–ç­‰ç»å†ä¸­ä½“ç°å‡ºçš„å¿«é€Ÿå­¦ä¹ èƒ½åŠ›ã€é€‚åº”æ–°ç¯å¢ƒå’Œæ–°æŒ‘æˆ˜çš„èƒ½åŠ›ã€‚
            *   ã€è§£å†³é—®é¢˜ä¸åˆ›æ–°æ€ç»´ã€‘ï¼šç®€å†ä¸­ä½“ç°å‡ºçš„åˆ†æé—®é¢˜ã€æå‡ºåˆ›æ–°è§£å†³æ–¹æ¡ˆã€ä¼˜åŒ–æµç¨‹ã€å…‹æœå›°éš¾çš„æ¡ˆä¾‹ã€‚è¿™å¯èƒ½ä½“ç°åœ¨ä»»ä½•é¢†åŸŸï¼Œä¸é™äºå²—ä½è¦æ±‚ã€‚
            *   ã€é¡¹ç›®ç®¡ç†ä¸æ‰§è¡ŒåŠ›ã€‘ï¼šå³ä½¿éé¡¹ç›®ç»ç†å²—ä½ï¼Œä½†ä»ç»„ç»‡æ´»åŠ¨ã€æ¨åŠ¨ä»»åŠ¡ã€åè°ƒèµ„æºã€è¾¾æˆç›®æ ‡ç­‰ç»å†ä¸­ä½“ç°å‡ºçš„è§„åˆ’ã€æ‰§è¡Œå’Œäº¤ä»˜èƒ½åŠ›ã€‚
            *   ã€æ²Ÿé€šåä½œä¸äººé™…å½±å“åŠ›ã€‘ï¼šä»å›¢é˜Ÿåˆä½œã€è·¨æ–‡åŒ–äº¤æµã€å®¢æˆ·æ²Ÿé€šã€é¢†å¯¼å°å›¢é˜Ÿã€å½±å“åŠ›æ„å»ºç­‰ç»å†ä¸­ä½“ç°å‡ºçš„è½¯æŠ€èƒ½ã€‚
            *   ã€è‡ªæˆ‘é©±åŠ¨ä¸ä¸»åŠ¨æ€§ã€‘ï¼šä»ä¸ªäººé¡¹ç›®ã€å¿—æ„¿æ´»åŠ¨ã€èŒä¸šå‘å±•è½¨è¿¹ã€è‡ªæˆ‘æå‡è¡Œä¸ºä¸­ä½“ç°å‡ºçš„å¼ºçƒˆè¿›å–å¿ƒã€ä¸»åŠ¨æ‰¿æ‹…è´£ä»»ã€è¿½æ±‚å“è¶Šçš„æ„æ„¿ã€‚

        3.  **é—´æ¥è¯æ®ä¸ä¾§é¢å°è¯ (Indirect Evidence & Lateral Proof):**
            *   ã€éä¼ ç»Ÿä½†æœ‰ä»·å€¼çš„ç»å†ã€‘ï¼šä¾‹å¦‚ï¼Œåœ¨éç›¸å…³é¢†åŸŸå–å¾—çš„æ˜¾è‘—æˆå°±ï¼ˆå¦‚ï¼šç»„ç»‡å¤§å‹ç¤¾å›¢æ´»åŠ¨ã€æˆåŠŸè¿è¥ä¸ªäººåšå®¢/ç¤¾åŒºã€åœ¨æŸä¸ªçˆ±å¥½é¢†åŸŸè¾¾åˆ°ä¸“å®¶æ°´å¹³ç­‰ï¼‰
            *   ã€è·¨å­¦ç§‘æˆ–å¤šå…ƒèƒŒæ™¯ã€‘ï¼šä¸åŒå¯»å¸¸çš„æ•™è‚²èƒŒæ™¯ç»„åˆæˆ–å·¥ä½œç»å†ï¼Œå¦‚ä½•å¸¦æ¥ç‹¬ç‰¹çš„è§†è§’æˆ–è§£å†³é—®é¢˜çš„æ–¹æ³•ï¼Œä»è€Œä¸ºå²—ä½å¢å€¼ã€‚

    æœ€ç»ˆç­”æ¡ˆæ ¼å¼è¦æ±‚ï¼š
    ä»¥jsonçš„æ ¼å¼è¾“å‡º è¯¥jsonä¸­å­˜åœ¨çš„keyä¸º "potential_score" 
    potential_score å¯¹åº”å­—æ®µç±»å‹ä¸º float è¡¨ç¤ºå­¦å†èƒŒæ™¯ä¸å²—ä½è¦æ±‚çš„åŒ¹é…å¾—åˆ†ï¼ˆæ»¡åˆ†100 80-100 è¡¨ç¤ºæ½œåŠ›å€¼å¾ˆå¤§ï¼Œ60-80 è¡¨ç¤ºå…·æœ‰ä¸€å®šæ½œåŠ›ã€‚60ä»¥ä¸‹ è¡¨ç¤ºçœ‹ä¸å‡ºç”¨æˆ·çš„æ½œåŠ›æ‰€åœ¨ï¼‰
    æ³¨æ„ä¸¥æ ¼æŒ‰ç…§è¯¥æ ¼å¼è¾“å‡º
        """
    system_prompt = SystemMessagePromptTemplate.from_template(system_prompt_template)
    prompt=ChatPromptTemplate.from_messages(
        [
            system_prompt,
            ('user',"""      
            ç”¨æˆ·è¾“å…¥ï¼š
            ç®€å†ä¿¡æ¯ï¼š
            {resume}
            èŒä½ä¿¡æ¯
            {job}
            """)
        ]
    )
    chain = prompt | llm_google | JsonOutputParser()
    chain = chain.with_config({'callbacks': llm_callback_handler})
    ans = await chain.ainvoke({'resume': text, 'job': job})
    print(ans)
    if isinstance(ans, dict) :
        print("æœªæ¥æ½œåŠ›åˆ†æç»“æŸ")
        return ans
    else:
        return {"potential_score": 60}


async def get_program_struct_score(resume: ResumeEvaluateInPut) -> dict:
    "å°†ç”¨æˆ·ç®€å†ä¸­çš„é¡¹ç›®å’Œå·¥ä½œç»å†æè¿°è¿›è¡Œä¹¦å†™ç»“æ„åŒ–ç¨‹åº¦è¿›è¡Œåˆ†æå¹¶è¿”å›ç»“æ„åŒ–åˆ†æ•°åˆ†æ•°ï¼ˆæ»¡åˆ†100åˆ†ï¼‰"
    print('æ­£åœ¨è¿›è¡Œç®€å†ç»“æ„åŒ–åˆ†æ')
    resume = resume.get('resume', {})
    resumes = resume.get('program', '') + '\n' + resume.get('work', '')
    if resumes != '':
        system_prompt_template = """
                ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„HRæ‹›è˜ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯é’ˆå¯¹ç”¨æˆ·ç®€å†ä¸­çš„é¡¹ç›®ç»å†ï¼ˆè‹¥å­˜åœ¨ï¼‰ä»¥åŠå·¥ä½œç»å†ï¼ˆè‹¥å­˜åœ¨ï¼‰è¿›è¡Œç»“æ„æ–¹é¢çš„**æ·±åº¦è¯„ä»·ä¸æ‰“åˆ†**ã€‚ä½ çš„è¯„ä»·å°†åŸºäºSTARæ³•åˆ™ï¼Œå¹¶åŠ›æ±‚æä¾›**å…·ä½“ã€å¯æ“ä½œã€æœ‰æ´å¯ŸåŠ›**çš„æ”¹è¿›å»ºè®®ã€‚
                ---
                **è¯„ä»·æ ¸å¿ƒæ³•åˆ™ï¼šSTARæ³•åˆ™ï¼ˆæ·±åº¦è§£è¯»ä¸è¯„ä¼°ç»´åº¦ï¼‰**
                ä»¥ä¸‹æ˜¯ä½ è¯„ä¼°æ¯ä¸ªSTARè¦ç´ æ—¶éœ€è¦è€ƒè™‘çš„æ·±åº¦ç»´åº¦ï¼š

                1.  **Situationï¼ˆæƒ…å¢ƒï¼‰**
                    *   **æ ¸å¿ƒè¦ç‚¹ï¼š** ç®€è¦æè¿°é¡¹ç›®/ä»»åŠ¡æ‰€å¤„çš„å®è§‚èƒŒæ™¯ã€é¢ä¸´çš„æŒ‘æˆ˜ã€å¸‚åœºéœ€æ±‚æˆ–é—®é¢˜ï¼Œä»¥åŠå…¶å¤æ‚æ€§æˆ–è§„æ¨¡ã€‚ç¡®ä¿è¯»è€…èƒ½ç†è§£ä¸ºä½•è¿™é¡¹å·¥ä½œæ˜¯å¿…è¦çš„ã€‚
                    *   **æ·±åº¦è€ƒé‡ç»´åº¦ï¼š**
                        *   **æ¸…æ™°æ€§ä¸ç®€æ´æ€§ï¼š** èƒŒæ™¯æè¿°æ˜¯å¦ä¸€ç›®äº†ç„¶ï¼Œæ²¡æœ‰å†—ä½™ä¿¡æ¯ï¼Ÿ
                        *   **é—®é¢˜å¯¼å‘æ€§ï¼š** æ˜¯å¦æœ‰æ•ˆé“ºå«äº†åç»­ä»»åŠ¡å’Œè¡ŒåŠ¨æ‰€è¦è§£å†³çš„â€œé—®é¢˜â€ï¼Ÿ
                        *   **å…³è”æ€§ä¸é‡è¦æ€§ï¼š** æ‰€æè¿°çš„æƒ…å¢ƒæ˜¯å¦ä¸ä»»åŠ¡å’Œç»“æœç´§å¯†ç›¸å…³ï¼Ÿæ˜¯å¦çªå‡ºäº†è¿™é¡¹å·¥ä½œçš„æˆ˜ç•¥æ„ä¹‰æˆ–ç´§è¿«æ€§ï¼Ÿ
                2.  **Taskï¼ˆä»»åŠ¡ï¼‰**
                    *   **æ ¸å¿ƒè¦ç‚¹ï¼š** æ˜ç¡®ä½ ä½œä¸ºä¸ªäººï¼ˆæˆ–å›¢é˜Ÿä¸­çš„ä½ ï¼‰æ‰€æ‰¿æ‹…çš„å…·ä½“ä»»åŠ¡ã€ç›®æ ‡æˆ–èŒè´£ã€‚å¼ºè°ƒç›®æ ‡çš„å¯è¡¡é‡æ€§æˆ–å…·ä½“æ€§ã€‚
                    *   **æ·±åº¦è€ƒé‡ç»´åº¦ï¼š**
                        *   **å…·ä½“æ€§ä¸å¯è¡¡é‡æ€§ï¼š** ä»»åŠ¡ç›®æ ‡æ˜¯å¦å…·ä½“ï¼ˆSMARTåŸåˆ™ï¼šSpecific, Measurable, Achievable, Relevant, Time-boundï¼‰ï¼Ÿ
                        *   **ä¸ªäººèŒè´£ç•Œå®šï¼š** æ˜¯å¦æ¸…æ™°åœ°ç•Œå®šäº†ä½ åœ¨å›¢é˜Ÿä¸­çš„ä¸ªäººèŒè´£å’Œè´¡çŒ®ï¼Œè€Œéæ³›æ³›è€Œè°ˆå›¢é˜Ÿç›®æ ‡ï¼Ÿ
                        *   **æŒ‘æˆ˜æ€§ä¸ä¸»åŠ¨æ€§ï¼š** ä»»åŠ¡æ˜¯å¦ä½“ç°äº†ä¸€å®šçš„æŒ‘æˆ˜æ€§ï¼Ÿä½ æ˜¯å¦åœ¨ä»»åŠ¡ä¸­å±•ç°äº†ä¸»åŠ¨æ€§ï¼Ÿ

                3.  **Actionï¼ˆè¡ŒåŠ¨ï¼‰**
                    *   **æ ¸å¿ƒè¦ç‚¹ï¼š** è¯¦ç»†è¯´æ˜ä½ é‡‡å–çš„å…·ä½“ç­–ç•¥ã€æŠ€æœ¯æ–¹æ³•ã€å·¥å…·ã€å†³ç­–è¿‡ç¨‹ä»¥åŠä½ åœ¨å…¶ä¸­æ‰®æ¼”çš„è§’è‰²å’Œè´¡çŒ®ã€‚é‡ç‚¹çªå‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€è§£å†³é—®é¢˜çš„æ–¹æ³•å’Œåˆ›æ–°ç‚¹ã€‚
                    *   **æ·±åº¦è€ƒé‡ç»´åº¦ï¼š**
                        *   **å…·ä½“æ€§ä¸å¯å¤ç°æ€§ï¼š** è¡ŒåŠ¨æè¿°æ˜¯å¦è¶³å¤Ÿå…·ä½“ï¼Œè®©è¯»è€…èƒ½æƒ³è±¡ä½ â€œæ˜¯å¦‚ä½•åšåˆ°çš„â€ï¼Ÿæ˜¯å¦æ¶µç›–äº†å…³é”®æ­¥éª¤å’ŒæŠ€æœ¯ç»†èŠ‚ï¼Ÿ
                        *   **ä¸ªäººè´¡çŒ®çªå‡ºï¼š** æ˜¯å¦æ¸…æ™°åœ°é˜è¿°äº†â€œä½ â€å…·ä½“åšäº†ä»€ä¹ˆï¼Œè€Œéä»…ä»…ç½—åˆ—å›¢é˜Ÿå·¥ä½œæˆ–é¡¹ç›®å†…å®¹ï¼Ÿ
                        *   **é—®é¢˜è§£å†³èƒ½åŠ›ï¼š** è¡ŒåŠ¨æ˜¯å¦ä½“ç°äº†ä½ åˆ†æé—®é¢˜ã€è§£å†³é—®é¢˜çš„æ€ç»´è¿‡ç¨‹å’Œèƒ½åŠ›ï¼Ÿæ˜¯å¦æœ‰å¯¹æŠ€æœ¯é€‰å‹ã€æ–¹æ¡ˆå¯¹æ¯”çš„æ€è€ƒï¼Ÿ
                        *   **åˆ›æ–°æ€§ä¸å½±å“åŠ›ï¼š** ä½ çš„è¡ŒåŠ¨æ˜¯å¦æœ‰ä»»ä½•åˆ›æ–°ç‚¹ï¼Ÿè¿™äº›è¡ŒåŠ¨å¦‚ä½•ç›´æ¥ä¿ƒæˆäº†ç»“æœï¼Ÿ

                4.  **Resultï¼ˆç»“æœï¼‰**
                    *   **æ ¸å¿ƒè¦ç‚¹ï¼š** ç”¨é‡åŒ–æ•°æ®æˆ–äº‹å®å±•ç¤ºè¡ŒåŠ¨å¸¦æ¥çš„å…·ä½“å½±å“ã€æˆæœå’Œä»·å€¼ã€‚ç»“æœåº”ç›´æ¥å¯¹åº”Så’ŒTä¸­çš„é—®é¢˜ä¸ç›®æ ‡ï¼Œå¹¶ä½“ç°ä½ çš„è´¡çŒ®ã€‚
                    *   **æ·±åº¦è€ƒé‡ç»´åº¦ï¼š**
                        *   **é‡åŒ–ä¸å¯è¡¡é‡æ€§ï¼š** ç»“æœæ˜¯å¦ç”¨å…·ä½“æ•°æ®ï¼ˆæ•°å­—ã€ç™¾åˆ†æ¯”ã€é‡‘é¢ã€æ—¶é—´ç­‰ï¼‰è¿›è¡Œäº†é‡åŒ–ï¼Ÿ
                        *   **å½±å“åŠ›ä¸ä»·å€¼ï¼š** ç»“æœæ˜¯å¦ä½“ç°äº†å¯¹ä¸šåŠ¡ã€ç”¨æˆ·ã€æ•ˆç‡ã€æˆæœ¬æˆ–æ”¶å…¥çš„å®é™…å½±å“ï¼Ÿæ˜¯å¦ä¸Så’ŒTä¸­æå‡ºçš„é—®é¢˜æˆ–ç›®æ ‡ç›´æ¥å¯¹åº”ï¼Ÿ
                        *   **å¯ä¿¡åº¦ä¸ç›¸å…³æ€§ï¼š** ç»“æœæ˜¯å¦çœŸå®å¯ä¿¡ï¼Ÿæ˜¯å¦ç›´æ¥ç”±ä½ æ‰€æè¿°çš„è¡ŒåŠ¨ä¿ƒæˆï¼Ÿ

                ---
                **è¯„ä»·æµç¨‹ä¸è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
                è¯·ä½ æ ¹æ®ä¸Šè¿°STARæ³•åˆ™çš„æ·±åº¦è€ƒé‡ç»´åº¦ï¼Œå¯¹ç”¨æˆ·ç®€å†ä¸­æä¾›çš„é¡¹ç›®ç»å†å’Œå·¥ä½œç»å†ï¼ŒæŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºã€‚
               è¯·å¯¹ç”¨æˆ·æä¾›çš„æ¯ä¸€æ®µé¡¹ç›®/å·¥ä½œç»å†ï¼Œç”Ÿæˆç‹¬ç«‹çš„è¯Šæ–­æŠ¥å‘Šã€‚æŠ¥å‘Šçš„ä¸»ä½“å†…å®¹å¿…é¡»ä½¿ç”¨**Markdownè¡¨æ ¼**æ¥å‘ˆç°ï¼Œä»¥ç¡®ä¿æ¸…æ™°å’Œç›´è§‚ã€‚

                ### è¯„ä»·é¡¹ç›®/å·¥ä½œç»å†ï¼š[é¡¹ç›®/å·¥ä½œç»å†åç§°]
                
                #### 1. STARæ³•åˆ™æ·±åº¦è¯Šæ–­è¡¨
                *ä½¿ç”¨ä¸€ä¸ªMarkdownè¡¨æ ¼ï¼Œå¯¹STARçš„å››ä¸ªè¦ç´ è¿›è¡Œé€ä¸€è¯Šæ–­ã€‚*
                
                | STAR è¦ç´  (Element) | ç°çŠ¶åˆ†æ (Current State Analysis) | æ”¹è¿›å»ºè®® (Improvement Suggestion) | è¦ç´ å¾—åˆ† (/25) |
                |---|---|---|---|
                | **S (æƒ…å¢ƒ)** | [æ­¤å¤„åˆ†æç®€å†åŸæ–‡ä¸­Séƒ¨åˆ†çš„ä¼˜ç¼ºç‚¹ã€‚ä¾‹å¦‚ï¼šä¼˜ç‚¹æ˜¯ç‚¹æ˜äº†é¡¹ç›®èƒŒæ™¯ï¼Œç¼ºç‚¹æ˜¯æœªèƒ½çªå‡ºæŒ‘æˆ˜çš„å¤æ‚æ€§ã€‚] | [æ­¤å¤„æä¾›å…·ä½“ã€å¯æ“ä½œçš„ä¿®æ”¹å»ºè®®ã€‚ä¾‹å¦‚ï¼šå»ºè®®å¢åŠ ä¸€å¥å…³äºå½“æ—¶å¸‚åœºç«äº‰æ¿€çƒˆæˆ–æŠ€æœ¯ç“¶é¢ˆçš„æè¿°ï¼Œä»¥å‡¸æ˜¾é¡¹ç›®çš„å¿…è¦æ€§ã€‚] | [ä¸ºè¯¥è¦ç´ æ‰“åˆ†] |
                | **T (ä»»åŠ¡)** | [æ­¤å¤„åˆ†æTéƒ¨åˆ†çš„ä¼˜ç¼ºç‚¹ã€‚ä¾‹å¦‚ï¼šæ¸…æ™°åœ°è¯´æ˜äº†ä¸ªäººè´Ÿè´£çš„æ¨¡å—ï¼Œä½†ç›®æ ‡ä¸å¤Ÿå…·ä½“ï¼Œç¼ºä¹å¯è¡¡é‡çš„KPIã€‚] | [æ­¤å¤„æä¾›å…·ä½“å»ºè®®ã€‚ä¾‹å¦‚ï¼šå»ºè®®å°†â€œè´Ÿè´£ä¼˜åŒ–æ€§èƒ½â€æ”¹ä¸ºâ€œç›®æ ‡æ˜¯å°†æ¥å£P99å»¶è¿Ÿä»500msé™ä½åˆ°200msä»¥å†…â€ã€‚] | [ä¸ºè¯¥è¦ç´ æ‰“åˆ†] |
                | **A (è¡ŒåŠ¨)** | [æ­¤å¤„åˆ†æAéƒ¨åˆ†çš„ä¼˜ç¼ºç‚¹ã€‚ä¾‹å¦‚ï¼šç½—åˆ—äº†ä½¿ç”¨çš„æŠ€æœ¯æ ˆï¼Œä½†ç¼ºä¹ä¸ªäººå†³ç­–è¿‡ç¨‹å’Œè§£å†³é—®é¢˜çš„ç»†èŠ‚ã€‚] | [æ­¤å¤„æä¾›å…·ä½“å»ºè®®ã€‚ä¾‹å¦‚ï¼šå»ºè®®è¡¥å……è¯´æ˜â€œä¸ºä»€ä¹ˆé€‰æ‹©Redisè€ŒéMemcachedâ€ï¼Œå¹¶æè¿°ä½ æ˜¯å¦‚ä½•è®¾è®¡ç¼“å­˜æ›´æ–°ç­–ç•¥æ¥è§£å†³æ•°æ®ä¸€è‡´æ€§é—®é¢˜çš„ã€‚] | [ä¸ºè¯¥è¦ç´ æ‰“åˆ†] |
                | **R (ç»“æœ)** | [æ­¤å¤„åˆ†æRéƒ¨åˆ†çš„ä¼˜ç¼ºç‚¹ã€‚ä¾‹å¦‚ï¼šæåˆ°äº†â€œæ€§èƒ½å¾—åˆ°æå‡â€ï¼Œä½†æè¿°è¿‡äºæ¨¡ç³Šï¼Œç¼ºä¹è¯´æœåŠ›ã€‚] | [æ­¤å¤„æä¾›å…·ä½“å»ºè®®ã€‚ä¾‹å¦‚ï¼šå¼ºçƒˆå»ºè®®é‡åŒ–æˆæœï¼Œå¦‚â€œæœ€ç»ˆæ¥å£P99å»¶è¿Ÿé™ä½è‡³180msï¼Œç³»ç»Ÿååé‡æå‡äº†150%â€ã€‚] | [ä¸ºè¯¥è¦ç´ æ‰“åˆ†] |

                #### 2. æ€»ä½“è¯„ä»·ä¸æ ¸å¿ƒå»ºè®®
                [åœ¨è¡¨æ ¼ä¸‹æ–¹ï¼Œå¯¹è¯¥æ®µç»å†è¿›è¡Œç®€è¦çš„æ€»ä½“è¯„ä»·ã€‚æŒ‡å‡ºæœ€ä¸»è¦çš„äº®ç‚¹å’Œæœ€éœ€è¦ä¼˜å…ˆæ”¹è¿›çš„éƒ¨åˆ†ã€‚ä¾‹å¦‚ï¼šæ•´ä½“æ¥çœ‹ï¼Œè¯¥é¡¹ç›®ç»å†å±•ç°äº†ä½ çš„æŠ€æœ¯æ‰§è¡ŒåŠ›ï¼Œä½†ä»·å€¼å‘ˆç°ï¼ˆResultï¼‰å’Œæ€è€ƒæ·±åº¦ï¼ˆActionï¼‰æ˜¯å½“å‰çš„ä¸»è¦çŸ­æ¿ã€‚å»ºè®®ä½ ä¼˜å…ˆå°†æˆæœé‡åŒ–ï¼Œå¹¶è¡¥å……æŠ€æœ¯å†³ç­–çš„æ€è€ƒè¿‡ç¨‹ã€‚]
                    è¾“å‡ºæ ¼å¼ï¼š
                    è¦æ±‚ä»¥jsonçš„æ ¼å¼è¾“å‡º ä½¿ç”¨çš„é”®åä¸º "resume_struct_evaluate"," resume_struct_score "
                    resume_struct_evaluate å­—æ®µå¯¹åº”ç±»å‹ä¸ºstr è¡¨ç¤ºä¸ºå¯¹ç®€å†å·¥ä½œæˆ–è€…é¡¹ç›®ç»å†çš„è¯„ä»·
                    resume_struct_score å­—æ®µç±»å‹ä¸ºfloat è¡¨ç¤ºå¯¹å†å·¥ä½œæˆ–è€…é¡¹ç›®ç»å†ä¹¦å†™çš„æ€»ä½“è¯„åˆ†ï¼ˆæ»¡åˆ†100,80-100 è¡¨ç¤ºä¹¦å†™çš„ç»“æ„å®Œå…¨ç¬¦åˆSTARç»“æ„ï¼Œåªæ˜¯å¯èƒ½æœ‰ä¸€ç‚¹ç‘•ç–µã€‚ 60-80 è¡¨ç¤ºåŸºæœ¬ç¬¦åˆSTARç»“æ„ï¼Œä½†æ˜¯å››å…ƒç´ ä¸­çš„æŸå‡ éƒ¨åˆ†ä¸ç¬¦åˆã€‚60ä»¥ä¸‹ è¡¨ç¤ºåŸºæœ¬ä¸ç¬¦åˆSTARç»“æ„ï¼Œç»“æ„æ··ä¹±ï¼Œå±äºä¸åŠæ ¼
                    """
        system_prompt = SystemMessagePromptTemplate.from_template(system_prompt_template)
        prompt=ChatPromptTemplate.from_messages(
            [
                system_prompt,
                ('user',"""
                    é¡¹ç›®ç»å†ï¼š
                    {program}
                """)
            ]
        )
        chain = prompt | llm_qwen | JsonOutputParser()
        chain = chain.with_config({'callbacks': llm_callback_handler})
        response=await chain.ainvoke({'program': resumes})
        print(response)
        if isinstance(response, dict) :
            print('ç®€å†ç»“æ„åŒ–åˆ†æç»“æŸ')
            return response

        else:
            return {'resume_struct_evaluate': '', 'resume_struct_score': 60.0}


async def get_experience_match_score(resume: ResumeEvaluateInPut) -> dict:
    print("æ­£åœ¨è¿›è¡Œç®€å†ç»éªŒåŒ¹é…åˆ†æ")
    resume = resume.get('resume', {})
    resumes = resume.get('program', '') + resume.get('work', '') + resume.get('awards', '')
    job = resume.get('job', '')
    prompt_template = """
    # è§’è‰²
ä½ æ˜¯ä¸€ä½é¡¶å°–çš„èŒä¸šå‘å±•é¡¾é—®å’Œç®€å†åˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ·±åº¦åˆ†æç”¨æˆ·ç®€å†ä¸ç›®æ ‡å²—ä½çš„åŒ¹é…åº¦ï¼Œå¹¶ç”Ÿæˆä¸€ä»½**ç»“æ„åŒ–ã€æ•°æ®é©±åŠ¨ã€é«˜åº¦å¯è¯»çš„JSONæ ¼å¼è¯„ä¼°æŠ¥å‘Š**ã€‚

# æ ¸å¿ƒä»»åŠ¡
æˆ‘å°†ä¸ºä½ æä¾›ã€ç®€å†ä¿¡æ¯ã€‘å’Œã€ç›®æ ‡å²—ä½ã€‘ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1.  **å‰æœŸè°ƒç ” (Research Phase)**ï¼šè°ƒç”¨æœç´¢å·¥å…·ï¼Œä¸ºåç»­çš„å»ºè®®éƒ¨åˆ†æ”¶é›†å¿…è¦çš„å¤–éƒ¨ä¿¡æ¯ã€‚
2.  **ç”ŸæˆæŠ¥å‘Š (Generation Phase)**ï¼šå°†æ‰€æœ‰åˆ†æå’Œå»ºè®®æ•´åˆåˆ°ä¸€ä¸ª**å•ä¸€çš„JSONå¯¹è±¡**ä¸­ã€‚ä½ å¿…é¡»**ç¡®ä¿â€œå‘å±•å»ºè®®â€éƒ¨åˆ†è¯¦ç»†ã€å…·ä½“åœ°æ•´åˆå¹¶é˜è¿°ä½ åœ¨ç¬¬ä¸€æ­¥ä¸­è°ƒç ”åˆ°çš„æ‰€æœ‰ä¿¡æ¯**ã€‚

# å·¥ä½œæµç¨‹

### ç¬¬ä¸€æ­¥ï¼šå‰æœŸè°ƒç ”ï¼ˆè°ƒç”¨æœç´¢å·¥å…·ï¼‰
åœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆä¹‹å‰ï¼Œä½ å¿…é¡»å…ˆè°ƒç”¨æœç´¢å·¥å…·å®Œæˆä»¥ä¸‹è°ƒç ”ä»»åŠ¡ï¼Œä¸ºâ€œæ·±åº¦å‘å±•è®¡åˆ’â€éƒ¨åˆ†åšå‡†å¤‡ï¼š
1.  **æœç´¢å¼€æºé¡¹ç›®**ï¼šæŸ¥æ‰¾å¹¶ç­›é€‰2-3ä¸ªä¸ã€ç›®æ ‡å²—ä½ã€‘æŠ€èƒ½è¦æ±‚**é«˜åº¦ç›¸å…³**çš„å¼€æºé¡¹ç›®ï¼ˆå¦‚GitHubä¸Šçš„é¡¹ç›®ï¼‰ï¼Œ**è®°å½•ä¸‹å…·ä½“çš„åç§°ã€é“¾æ¥åŠå…¶æ ¸å¿ƒæŠ€æœ¯ç‰¹ç‚¹**ã€‚
2.  **æœç´¢ç«èµ›æ´»åŠ¨**ï¼šæŸ¥æ‰¾å¹¶ç­›é€‰1-2ä¸ªä¸ã€ç›®æ ‡å²—ä½ã€‘ç›¸å…³çš„ä¸“ä¸šæ¯”èµ›ã€æŠ€æœ¯æŒ‘æˆ˜èµ›æˆ–é‡è¦çš„è¡Œä¸šä¼šè®®ï¼Œ**è®°å½•ä¸‹å…·ä½“åç§°å’Œå®˜ç½‘é“¾æ¥**ã€‚
3.  **æœç´¢å­¦ä¹ èµ„æºä¸ç¤¾åŒº**ï¼šæŸ¥æ‰¾å¹¶ç­›é€‰ä¸ã€ç›®æ ‡å²—ä½ã€‘æ ¸å¿ƒæŠ€èƒ½ç›¸å…³çš„ï¼š
    *   1-2ä¸ªé«˜è´¨é‡çš„åœ¨çº¿è¯¾ç¨‹æˆ–æ·±åº¦æ•™ç¨‹ã€‚
    *   1-2ä½è¡Œä¸šå†…çš„æŠ€æœ¯ä¸“å®¶æˆ–å…¶æœ‰å½±å“åŠ›çš„æŠ€æœ¯åšå®¢ã€‚
    *   1-2ä¸ªæ´»è·ƒçš„çº¿ä¸ŠæŠ€æœ¯ç¤¾åŒºï¼ˆå¦‚Slack/Discordé¢‘é“ã€ä¸“ä¸šè®ºå›ï¼‰ã€‚

### ç¬¬äºŒæ­¥ï¼šç”ŸæˆJSONè¯„ä¼°æŠ¥å‘Š
è°ƒç ”å®Œæˆåï¼Œä¸¥æ ¼æŒ‰ç…§#è¾“å‡ºæ ¼å¼çš„è¦æ±‚ï¼Œç”Ÿæˆæœ€ç»ˆçš„JSONæŠ¥å‘Šã€‚

#### 1. è¯¦ç»†åŒ¹é…åº¦åˆ†æ (Detailed Match Analysis)
**åˆ†æå†…å®¹**ï¼šè¯„ä¼°ç®€å†ä¸­çš„ç»éªŒã€æŠ€èƒ½ä¸å²—ä½è¦æ±‚çš„å¥‘åˆåº¦ã€‚
è¾“å‡ºæ ¼å¼ï¼š
ä½¿ç”¨ä¸€ä¸ªMarkdownè¡¨æ ¼ï¼Œè¿›è¡Œè¯„ä¼°
|---|---|---|---|
| è¯„ä¼°é¡¹ (Item) | åŒ¹é…çŠ¶æ€ (Status) | è¯¦ç»†åˆ†æ (Analysis) |
| [åœ¨æ­¤å¤„å¡«å……åˆ†æå†…å®¹] | [åœ¨æ­¤å¤„å¡«å……åˆ†æå†…å®¹] | [åœ¨æ­¤å¤„å¡«å……åˆ†æå†…å®¹] |
| ... | ... | ... |

#### 2. åŸºäºè°ƒç ”çš„æ·±åº¦å‘å±•è®¡åˆ’ (In-depth Development Plan Based on Research)
*   **åˆ†æå†…å®¹**ï¼š**ä½ å¿…é¡»å°†ç¬¬ä¸€æ­¥è°ƒç ”åˆ°çš„æ‰€æœ‰ç»“æœï¼Œæ·±åº¦æ•´åˆå¹¶é˜è¿°åˆ°ä¸‹æ–¹çš„è¡¨æ ¼ä¸­**ã€‚å»ºè®®ä½ å¯ä»¥å€Ÿé‰´ä½ çš„è°ƒç ”ç»“æœï¼Œå¹¶æä¾›æ¸…æ™°çš„å®æ–½è·¯å¾„ã€‚
è¾“å‡ºæ ¼å¼ï¼š
*ä½¿ç”¨Markdownè¡¨æ ¼æ¥æ•´åˆæ‰€æœ‰å»ºè®®ã€‚*
|---|---|---|---|
| å»ºè®®ç±»åˆ« (Category) | å…·ä½“å»ºè®® (Suggestion) | è°ƒç ”æ¥æº/é“¾æ¥ (Source/Link from Research) | å®æ–½è·¯å¾„ (Implementation Path) | é¢„æœŸæ”¶ç›Š (Expected Benefit) |
| **é¡¹ç›®å®è·µ** | è´¡çŒ®æˆ–å¤ç° `milvus-io/milvus` é¡¹ç›®ä¸­çš„éƒ¨åˆ†åŠŸèƒ½ï¼Œç‰¹åˆ«æ˜¯å…¶å‘é‡ç´¢å¼•æˆ–æ•°æ®ç®¡ç†æ¨¡å—ã€‚ | `github.com/milvus-io/milvus` | 1. **Forkå¹¶æ­å»º**ï¼šåœ¨æœ¬åœ°æˆåŠŸè¿è¡ŒMilvusã€‚ <br> 2. **ä»£ç ç ”è¯»**ï¼šé‡ç‚¹é˜…è¯»`internal/core`ç›®å½•ï¼Œç†è§£å…¶æ ¸å¿ƒæ¶æ„ã€‚ <br> 3. **ä»»åŠ¡åˆ‡å…¥**ï¼šä»æ ‡è®°ä¸º `good first issue` æˆ– `help wanted` çš„ä»»åŠ¡å¼€å§‹ï¼Œå°è¯•æäº¤ä¸€ä¸ªå°çš„PRã€‚ | è·å¾—ä¸šç•Œé¢†å…ˆçš„å‘é‡æ•°æ®åº“é¡¹ç›®ç»éªŒï¼Œè¿™ä¸å¤§æ¨¡å‹ã€æœç´¢æ¨èç­‰å‰æ²¿å²—ä½éœ€æ±‚é«˜åº¦ç›¸å…³ï¼Œæ˜¯ç®€å†çš„å·¨å¤§åŠ åˆ†é¡¹ã€‚ |
| **ç«èµ›æ´»åŠ¨** | å‚åŠ æˆ–å¤ç›˜â€œKaggleâ€ä¸Šçš„â€œLLM - Science Examâ€ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³çš„ç«èµ›ã€‚ | `kaggle.com/competitions` | 1. **èµ›é¢˜ç†è§£**ï¼šæ·±å…¥åˆ†ææ¯”èµ›çš„è¯„ä¼°æŒ‡æ ‡å’Œæ•°æ®é›†ã€‚ <br> 2. **æ–¹æ¡ˆå¤ç°**ï¼šå­¦ä¹ å¹¶å¤ç°Top 10%é€‰æ‰‹çš„å¼€æºè§£å†³æ–¹æ¡ˆã€‚ <br> 3. **åˆ›æ–°å®è·µ**ï¼šåœ¨å¤ç°åŸºç¡€ä¸Šï¼Œå°è¯•æ”¹è¿›æ¨¡å‹æˆ–ç‰¹å¾å·¥ç¨‹ï¼Œå¹¶è®°å½•å®éªŒç»“æœã€‚ | åœ¨å®è·µä¸­æ£€éªŒå’Œæå‡ä½ çš„æ¨¡å‹è°ƒä¼˜ã€ç‰¹å¾å·¥ç¨‹å’Œè§£å†³å¤æ‚é—®é¢˜çš„èƒ½åŠ›ï¼Œè·å¾—æœ‰è¯´æœåŠ›çš„æ•°æ®æˆæœã€‚ |
| **ä¸“ä¸šå­¦ä¹ ä¸ç¤¾åŒºå‚ä¸** | æ·±å…¥å­¦ä¹ `Hugging Face`å®˜æ–¹è¯¾ç¨‹ï¼Œå¹¶å…³æ³¨å…¶æ ¸å¿ƒå¼€å‘è€…`Thomas Wolf`çš„æŠ€æœ¯åˆ†äº«ã€‚ | - `huggingface.co/learn/nlp-course` <br> - Twitter: `@Thom_Wolf` | 1. **ç³»ç»Ÿå­¦ä¹ **ï¼šå®ŒæˆHugging Face NLPè¯¾ç¨‹ï¼Œå¹¶åŠ¨æ‰‹å®Œæˆæ‰€æœ‰ä»£ç å®éªŒã€‚ <br> 2. **ä¸»åŠ¨å…³æ³¨**ï¼šåœ¨Twitteræˆ–åšå®¢ä¸Šå…³æ³¨ä¸“å®¶çš„æœ€æ–°åŠ¨æ€ï¼Œç†è§£å‰æ²¿æŠ€æœ¯è¶‹åŠ¿ã€‚ <br> 3. **ç¤¾åŒºäº’åŠ¨**ï¼šåŠ å…¥Hugging Faceçš„Discordæˆ–è®ºå›ï¼Œå‚ä¸æŠ€æœ¯è®¨è®ºï¼Œå°è¯•å›ç­”æ–°æ‰‹é—®é¢˜ã€‚ | ç³»ç»Ÿæ€§åœ°æŒæ¡SOTAï¼ˆæœ€å…ˆè¿›çš„ï¼‰NLPå·¥å…·åº“ï¼Œæ¥è½¨è¡Œä¸šæ ‡å‡†ï¼Œå¹¶é€šè¿‡ç¤¾åŒºå»ºç«‹ä¸ªäººæŠ€æœ¯å“ç‰Œå’Œå½±å“åŠ›ã€‚ |


#### 3. æ€»ç»“ä¸å±•æœ› (Summary & Outlook)
*   **åˆ†æå†…å®¹**ï¼šå¯¹æ•´ä½“è¯„ä¼°è¿›è¡Œç®€è¦æ€»ç»“ï¼Œå¹¶ç»™å‡ºé¼“åŠ±æ€§çš„å±•æœ›å’Œä¸‹ä¸€æ­¥è¡ŒåŠ¨çš„æ ¸å¿ƒå»ºè®®ã€‚
*   **å‘ˆç°æ–¹å¼**ï¼šä½¿ç”¨å¸¸è§„çš„Markdownæ–‡æœ¬æ ¼å¼ã€‚

---

# è¾“å‡ºæ ¼å¼
ä½ çš„æœ€ç»ˆè¾“å‡º**å¿…é¡»**æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„ã€æ²¡æœ‰ä»»ä½•å¤šä½™å­—ç¬¦çš„JSONæ ¼å¼ï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªé”®ï¼š`experience_evaluate` å’Œ `experience_score`ã€‚

*   `"experience_evaluate"`: (string)
    *   å…¶å€¼æ˜¯ä¸€ä¸ª**åŒ…å«å®Œæ•´è¯„ä¼°æŠ¥å‘Šçš„å­—ç¬¦ä¸²**ã€‚
*   `"experience_score"`: (float)
    *   å…¶å€¼æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºç®€å†ä¸å²—ä½çš„åŒ¹é…åº¦æ€»åˆ†ï¼ˆæ»¡åˆ†100ï¼‰ã€‚
    *   è¯„åˆ†æ ‡å‡†ï¼š80-100åˆ† (é«˜åº¦åŒ¹é…), 60-80åˆ† (åŸºæœ¬åŒ¹é…), 60åˆ†ä»¥ä¸‹ (åŒ¹é…åº¦è¾ƒä½)ã€‚
    """
    agent = create_react_agent(llm, [web_search], prompt=prompt_template)
    agent= agent.with_config({'callbacks': llm_callback_handler})
    response = await agent.ainvoke({'messages':resumes+'åº”è˜å²—ä½ä¿¡æ¯ï¼š\n'+ job})
    try:
        ans=response['messages'][-1]
        parse=JsonOutputParser()
        if isinstance(ans,AIMessage):
            ans=parse.parse(ans.content)
            print(ans)
            print("ç®€å†åŒ¹é…åˆ†æç»“æŸ")
            return ans
    except Exception as e:
        print(e)


def create_resume_radar(resume: ResumeEvaluateState) -> dict:
    """
    åˆ›å»ºç®€å†è¯„ä»·é›·è¾¾å›¾ï¼ˆäº”ç»´åº¦ç‰ˆï¼‰
    """
    structural_score = resume.get('resume_struct_score', 0)
    technical_score = resume.get('technology_stack_score', 0)
    school_score = resume.get('school_score', 0)
    experience_score = resume.get('experience_score', 0)
    potential_score = resume.get('potential_score', 0)
    save_path = 'é›·è¾¾å›¾/five_dimension_radar.png'
    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']
    plt.rcParams['axes.unicode_minus'] = False
    labels = ['ç®€å†ç»“æ„', 'ç»å†åŒ¹é…', 'æŠ€æœ¯èƒ½åŠ›', 'å­¦æ ¡èƒŒæ™¯', 'å‘å±•æ½œåŠ›']
    data = [structural_score, experience_score, technical_score, school_score, potential_score]
    num_vars = len(labels)
    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False)
    data = np.concatenate((data, [data[0]]))
    angles = np.concatenate((angles, [angles[0]]))
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))
    fig.patch.set_facecolor('white')
    ax.set_facecolor('white')
    grid_color = '#e0e0e0'
    text_color = '#333333'
    accent_color = '#2563eb'
    for i in range(1, 6):
        ax.plot(angles, [i * 20] * len(angles), color=grid_color, alpha=0.7, linewidth=1, linestyle='--')
    ax.fill(angles, [100] * len(angles), facecolor='#f5f5f5', alpha=0.3)
    ax.fill(angles, [80] * len(angles), facecolor='#f0f0f0', alpha=0.3)
    ax.fill(angles, [60] * len(angles), facecolor='#ebebeb', alpha=0.3)
    ax.fill(angles, [40] * len(angles), facecolor='#e6e6e6', alpha=0.3)
    ax.fill(angles, [20] * len(angles), facecolor='#e1e1e1', alpha=0.3)
    line, = ax.plot(angles, data, color=accent_color, linewidth=3, marker='o',
                    markersize=10, markerfacecolor=accent_color, markeredgecolor='white')
    line.set_path_effects([
        patheffects.withStroke(linewidth=5, foreground=accent_color, alpha=0.2),
        patheffects.withStroke(linewidth=8, foreground=accent_color, alpha=0.1)
    ])
    ax.fill(angles, data, facecolor=accent_color, alpha=0.15)
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(labels, color=text_color, fontsize=12, fontweight='bold')
    ax.set_rlabel_position(0)
    plt.yticks([20, 40, 60, 80, 100], ["20", "40", "60", "80", "100"],
               color=text_color, size=10, fontweight='bold')
    plt.ylim(0, 110)
    for angle, value in zip(angles[:-1], data[:-1]):
        ax.text(angle, value + 7, f"{value}",
                color='white', ha='center', va='center',
                fontsize=11, fontweight='bold',
                bbox=dict(facecolor=accent_color, alpha=0.9, edgecolor='none', boxstyle='round,pad=0.2'))
    center_circle = Circle((0.5, 0.5), 0.05, transform=ax.transAxes,
                           color=accent_color, alpha=0.8, zorder=10)
    fig.add_artist(center_circle)
    title = ax.set_title('ç®€å†ç»¼åˆè¯„ä»·é›·è¾¾å›¾', color=text_color, fontsize=18, fontweight='bold', pad=30)
    title.set_path_effects([
        patheffects.withStroke(linewidth=3, foreground=accent_color, alpha=0.3)
    ])
    for i in range(36):
        angle = np.radians(i * 10)
        ax.plot([angle, angle], [0, 105], color=grid_color, alpha=0.3, linewidth=0.5)
    outer_circle = Circle((0.5, 0.5), 0.45, transform=ax.transAxes,
                          facecolor='none', edgecolor=accent_color, alpha=0.3, linewidth=2)
    fig.add_artist(outer_circle)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor=fig.get_facecolor())
    plt.close()
    print(f"äº”ç»´è¯„ä»·é›·è¾¾å›¾å·²ä¿å­˜è‡³: {save_path}")
    return {'resume_radar_path': save_path}
def rounter(state:ResumeEvaluateState):
    resume_struct_score = state['resume_struct_score']
    experience_score = state['experience_score']
    school_score = state['school_score']
    potential_score = state['potential_score']
    technology_stack_score = state['technology_stack_score']
    if school_score < 60:
        print('å¾ˆæŠ±æ­‰çš„é€šçŸ¥æ‚¨ï¼Œæ‚¨å¹¶æœªé€šè¿‡æˆ‘å…¬å¸çš„ç®€å†ç­›é€‰ã€‚')
        return Command(
            goto=END,
            update={'page':False}
        )
    final_score = resume_struct_score * 0.1 + experience_score * 0.35 + school_score * 0.15 + potential_score * 0.1 + technology_stack_score * 0.3
    print(final_score)
    if final_score < 75:
        print('å¾ˆæŠ±æ­‰çš„é€šçŸ¥æ‚¨ï¼Œæ‚¨å¹¶æœªé€šè¿‡æˆ‘å…¬å¸çš„ç®€å†ç­›é€‰ã€‚')
        return Command(
            goto=END,
            update={'page':False}
        )
    else:
        print('æ­å–œä½ æˆåŠŸé€šè¿‡ç®€å†åˆç­›,å³å°†è¿›å…¥ç®—æ³•ç¬”è¯•æµ‹è¯•')
        return Command(
            goto=END,
            update={'page':True}

        )
def create_resume_evaluate_agent():
    agent=StateGraph(ResumeEvaluateState,input_schema=ResumeEvaluateInPut)
    agent.add_node('Start',lambda x:{})
    agent.add_node("get_potential_score", get_potential_score)
    agent.add_node("get_school_score", get_school_score)
    agent.add_node("get_resume_key_score", get_resume_key_score)
    agent.add_node("get_experience_match_score", get_experience_match_score)
    agent.add_node("get_program_struct_score", get_program_struct_score)
    agent.add_node('create_radar', create_resume_radar)
    agent.add_node('create_resume_assessment_report', create_resume_assessment_report)
    parallel_nodes = [
        "get_potential_score",
        "get_school_score",
        "get_resume_key_score",
        "get_experience_match_score",
        "get_program_struct_score",
    ]
    agent.set_entry_point('Start')
    for node in parallel_nodes:
        agent.add_edge('Start',node)
        agent.add_edge(node,'create_radar')
    agent.add_edge('create_radar','create_resume_assessment_report')
    agent.add_conditional_edges('create_resume_assessment_report',rounter)
    agent=agent.compile()
    return agent


if __name__ == '__main__':
    create_resume_evaluate_agent()
